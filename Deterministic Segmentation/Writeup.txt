Robert Werthman
CSCI 5832: Assignment 1

Run 'werthman-assgn1.py' with Python 2.
It takes two command line arguments:
	The first is the absolute path to the lexicon
	The second is the absolute path to the hashtags
	The third is the absolute path to the reference hashtag output used for WER calculation 

Failures from Part 1:
	After running the regular Max Match algorithm from part one I noticed a few
	patterns:
	1) Single letters would be words by themselves
	2) Typos and other non-english words would be separated into words
	3) Looking for the largest word in the beginning of the hashtag was not always correct
	

Changes I made to the MaxMatch strategy:
    1) Instead of taking the largest word that fits take the smallest word greater >= 2 characters *this was not an improvement*
    2) Max match backwards instead of forwards *improved WER from .60 to .35*
    3) Don't add spaces after characters not found in corpus *improved WER from .39 to .35*
    4) Run maxmatch both ways and take output with fewer words, if same number take reverse maxmatch *did not try this*
    5) Check for the largest string in any part of the hashtag instead of just at the front or end *improved WER from .35 to .29*
    
Changes to gready nature
    1) If there is a single letter at the end of the string combine it with the previous word *greedy nature changed, improved WER from .66 to .60* 

Changes to lexicon
    1) Do not take single characters to be words in the word list/lexicon *this did not improve anything*
    2) Clean up lexicon/corpus/wordlist to not include typos *did this in the line below*
    3) Remove and insert as many words as possible to correct the output *improve WER from .29 to .11*
    
Lowest measured WER from the final test set was .2075.  This WER is only the result of changing the algorithm and not the lexicon.

    