Part 1:
----------------
1. With the original Naive Bayes from homework 2, I was labeling around ** of the test reviews correctly.



Part 2:
-------------------------
1. I tried to stem the words and the percentage I got correct barely improved (went up a %1 point).
2. I tried to find patterns with POS tagging and according to an article [3].
	Typically a fake reviews had more verbs relative to nouns.  I did find this but I was not sure what to do with that information.
3. I then tried based on that same article and forum posts on moodle to use a support vector classifier and the chi squared test feature extractor
	of the scikit library.  This labeled around *** of the reviews correctly.
4. I tried other classifiers like Multinomial Bayes and Stochastic Gradient Descent but they gave about the same percentage
	as support vector.
5. The classifier that was somewhat better was the PassiveAggressiveClassifier which labeled about *** of the test reviews correctly.


Sources:
----------
[1] https://stackoverflow.com/questions/19484499/text-mining-with-svm-classifier
	- Explained what I should use to implement the support vector classifier.
[2] http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html#example-text-document-classification-20newsgroups-py
	- Showed me how to implement the support vector classifier.
[3] https://aclweb.org/anthology/N/N13/N13-1053.pdf
	- Described how to get more accurate results with deception detection