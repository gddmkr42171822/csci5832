'''
Robert Werthman

Naive-Bayes with add one smoothing
P(word|-) = (frequency of the word in negative reviews class + 1)/
            (total count of all words in negative reviews class + number of words in entire vocabulary of training set (V)) 
P(review|-) = log of the probability of each of the words being negative added together
'''
import re
import math

# Words to remove that don't have any sentiment
stopList = ['the','and','a','was','to','i','in','of','is','it']

def checkOutput(outputFile, answerFile):
    wrongIDs = 0
    answers = {}
    output = {}
    # Read in the IDs and tags from the correct answers file
    f = open(answerFile, 'r')
    for line in f:
        line = line.strip().split('\t')
        answers[line[0]] = line[1]
    f.close()
    # Read in the IDs and tags from the output generated by naive bayes
    f = open(outputFile)
    for line in f:
        line = line.strip().split('\t')
        output[line[0]] = line[1]
    # Check if each ID has the correct sentiment tag
    for key in output:
        if key in answers:
            if output[key] == answers[key]:
                print "{0} is correct.".format(key)
            else:
                print "{0} is incorrect.".format(key)
                wrongIDs += 1
    print 'Number of wrong IDs: {0}'.format(wrongIDs)

def wordCount(file):
    '''
    Return a dictionary of the word counts in a file
    '''
    d = {}
    f = open(file, 'r')
    for line in f:
        # Remove end of punctuation
        line = re.sub('[.,!?]', '', line)
        # Make everything lowercase
        line = line.lower()
        # Split words on spaces in the line
        line = line.strip().split()
        # Remove the ID-.... from the line
        line = line[1:]
        # Create a dictionary with the key being the word and the value being the count
        for word in line:
            if word in d:
                d[word] += 1
            else:
                d[word] = 1
    # Remove any words from the stop list
    for word in stopList:
        d.pop(word)
    f.close()
    return d        

def gatherReviews(file):
    '''
    Return a dictionary of the reviews in a file
    '''
    d = {}
    f = open(file,'r')
    for line in f:
        # Remove end of punctuation
        line = re.sub('[.,!?]', '', line)
         # Make everything lowercase
        line = line.lower()
        # Split words on spaces in the line
        line = line.split()
        # Put review ID in the dictionary as key and rest of the words of the review as value
        d[line[0]] = line[1:]
        # Remove words in the review from the stop list
        cleanedList = [word for word in d[line[0]] if word not in stopList]
        d[line[0]] = cleanedList
        
    f.close()
    return d

def probabilityOfClass(reviewClass,review,vocabulary):
    '''
    Returns a list of probabilities for each word in a review given a class
    '''
    listOfProbabilities = []
    # Add up all the words in a review class
    totalCountOfWordsInClass = 0
    for word in reviewClass:
        totalCountOfWordsInClass += reviewClass[word]
    # Calculate the probability of each word given a review class
    for word in review:
        freqOfWordInClass = 0
        if word in reviewClass:
            freqOfWordInClass = reviewClass[word]
            #print word
        else:
            freqOfWordInClass = 0
        probabilityOfWord = ((freqOfWordInClass+1)*1.0)/((totalCountOfWordsInClass+len(vocabulary))*1.0)
        listOfProbabilities.append(math.log(probabilityOfWord))
    return listOfProbabilities
        
    
    



def main():
    # Create a dictionary with all the words in the positive review set
    posWords = wordCount('postest_reviews.txt')
    # Create a dictionary with all the words in the negative review set
    negWords = wordCount('negtest_reviews.txt')
    # Create a dictionary of all the words in the training set
    vocabulary = posWords.copy()
    vocabulary.update(negWords)
    # Retrieve the reviews from a file and add them in a dictionary with the review ID as the key
    #reviews = gatherReviews('test-reviews.txt')
    # Create an output file for the sentiment analysis of the reviews
    f = open('werthman-robert-assgn2-out.txt', 'w')
    # Check if the reviews are positive or negative
    reviews = gatherReviews('test-reviews.txt')
    for review in reviews:
        # Get a list of the log of the probabilities for each word in the review
        # for each sentiment class
        negProb = probabilityOfClass(negWords, reviews[review], vocabulary)
        posProb = probabilityOfClass(posWords, reviews[review], vocabulary)
        # Add the list of probabilities together for each class
        negProb = reduce(lambda x,y: x+y, negProb)
        posProb = reduce(lambda x,y: x+y, posProb)
        # Evaluate the sentiment of each review by comparing the probabilities of each class
        # for that review
        if posProb > negProb:
            f.write('{0}\tPOS\n'.format(review.upper()))
            #print "{0}. {1}\tPOS".format(line,review)
        elif negProb > posProb:
            f.write('{0}\tNEG\n'.format(review.upper()))
            #print "{0}. {1}\tNEG".format(line,review)
    f.close()
    
    checkOutput('werthman-robert-assgn2-out.txt','answers.txt')
    

if __name__ == '__main__':
    main()